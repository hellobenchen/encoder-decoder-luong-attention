# encoder-decoder-luong-attention
A batch implementation of the encoder-decoder model with luong attention
